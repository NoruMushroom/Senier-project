{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "img1 = r\"C:\\Users\\apf_temp_admin\\Pictures\\20200712_160810.jpg\"\n",
    "a = DeepFace.represent(img_path = img1, model_name = \"ArcFace\",detector_backend = \"retinaface\",enforce_detection = False\n",
    "                       ,normalization = \"ArcFace\")\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer : [(None, 112, 112, 3)]\n"
     ]
    }
   ],
   "source": [
    "from deepface.basemodels import ArcFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from retinaface import RetinaFace\n",
    "from retinaface.commons import postprocess\n",
    "import numpy as np\n",
    "from keras_preprocessing import image\n",
    "from deepface.commons import functions\n",
    "from deepface.commons import functions, realtime, distance as dst\n",
    "model = ArcFace.loadModel()\n",
    "print(\"input layer : \" + str(model.layers[0].input_shape)) # input layer\n",
    "\n",
    "# functions.preprocess_face()\n",
    "def ab(img1, normalization=\"base\"):\n",
    "    read_img = cv2.imread(img1)\n",
    "    img = cv2.cvtColor(read_img, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(read_img)\n",
    "    if type(faces) == dict:\n",
    "        box, landmarks, score = (faces['face_1']['facial_area'],\n",
    "                                faces['face_1']['landmarks'],\n",
    "                                faces['face_1']['score'])\n",
    "        img= read_img[box[1]: box[3], box[0]:box[2]].copy()\n",
    "        img = postprocess.alignment_procedure(img, landmarks['right_eye'], landmarks['left_eye'],landmarks['nose'])\n",
    "    \n",
    "    if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "        factor_0 = 112 / img.shape[0]\n",
    "        factor_1 = 112 / img.shape[1]\n",
    "        factor = min(factor_0, factor_1)\n",
    "\n",
    "        dsize = (int(img.shape[1] * factor), int(img.shape[0] * factor))\n",
    "        img = cv2.resize(img, dsize)\n",
    "        # Then pad the other side to the target size by adding black pixels\n",
    "        diff_0 = 112 - img.shape[0]\n",
    "        diff_1 = 112 - img.shape[1]\n",
    "    \n",
    "        img = np.pad(img, ((diff_0 // 2, diff_0 - diff_0 // 2), (diff_1 // 2, diff_1 - diff_1 // 2), (0, 0)), 'constant')\n",
    "\n",
    "    #------------------------------------------\n",
    "\n",
    "    #double check: if target image is not still the same size with target.\n",
    "    if img.shape[0:2] != 112:\n",
    "        img = cv2.resize(img, (112,112))\n",
    "    #---------------------------------------------------\n",
    "\n",
    "    #normalizing the image pixels\n",
    "    img_pixels = image.img_to_array(img) #what this line doing? must?\n",
    "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "    img_pixels /= 255 #normalize input in [0, 1]\n",
    "    img = functions.normalize_input(img = img_pixels, normalization = normalization)\n",
    "    embedding = model.predict(img)[0].tolist()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4885533245591477"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = r\"C:\\Users\\apf_temp_admin\\Pictures\\20200712_160810.jpg\"\n",
    "img2 = r\"D:\\Mask_Project\\user_img\\NoMask\\20170734\\20170734_006.jpg\"\n",
    "a = DeepFace.represent(img_path = img1, model_name = \"ArcFace\",detector_backend = \"retinaface\",enforce_detection = False\n",
    "                       ,normalization = \"ArcFace\")\n",
    "b = ab(img2,normalization=\"ArcFace\")\n",
    "distance = dst.findCosineDistance(a, b)\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.4885533245591477,\n",
       " 'threshold': 0.68,\n",
       " 'model': 'ArcFace',\n",
       " 'detector_backend': 'retinaface',\n",
       " 'similarity_metric': 'cosine'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "af = DeepFace.verify(img1_path = img1,img2_path=img2,model_name=\"ArcFace\",\n",
    "                     detector_backend = 'retinaface',\n",
    "                     normalization = 'ArcFace',\n",
    "                     enforce_detection = False)\n",
    "af"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "208828bd9ed720bd60b6bef9245f8f28d89e3548672251c16998ce65c07cc472"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
